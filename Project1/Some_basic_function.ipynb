{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### image read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image_examples/lena.png\")\n",
    "cv2.imshow(winname=\"Lena Image\",mat=img)\n",
    "cv2.waitKey(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### read video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# framWidth = 640\n",
    "# framHeight = 480\n",
    "# cap = cv2.VideoCapture(\"image_examples/cars.avi\")\n",
    "# while cap.isOpened():\n",
    "#     success,frame = cap.read()\n",
    "#     frame_size = cv2.resize(src=frame,dsize=(framWidth,framHeight))\n",
    "#     cv2.imshow(winname=\"Test Video\",mat=frame_size)\n",
    "#     if cv2.waitKey(1)==13:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "#### read webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frameWidth = 640\n",
    "# frameHeight = 480\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3,frameWidth)\n",
    "# cap.set(4,frameHeight)\n",
    "# cap.set(10,150)\n",
    "\n",
    "# while True:\n",
    "#     success,frame = cap.read()\n",
    "#     cv2.imshow(\"Result\",frame)\n",
    "#     if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(filename=\"image_examples/lena.png\")\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "# print(kernel)\n",
    "\n",
    "# convert into gray\n",
    "imgGray = cv2.cvtColor(src=img,code=cv2.COLOR_BGR2GRAY)\n",
    "# convert into blur\n",
    "imgBlur = cv2.GaussianBlur(src=imgGray,ksize=(9,9),sigmaX=0) # ksize = kernel size\n",
    "# imgBlur = cv2.GaussianBlur(img,(9,9),0)\n",
    "# convert into canny\n",
    "imgCanny = cv2.Canny(image=img,threshold1=150,threshold2=200)\n",
    "# convert into dialation\n",
    "imgDialation = cv2.dilate(imgCanny,kernel,iterations=1) # iterations remove the thikness from image\n",
    "# convert into eroded\n",
    "imgEroded = cv2.erode(imgDialation,kernel,iterations=1)\n",
    "\n",
    "\n",
    "# display img\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "cv2.imshow(\"Gray Image\",imgGray)\n",
    "cv2.imshow(\"Blur Image\",imgBlur)\n",
    "cv2.imshow(\"Canny Image\",imgCanny)\n",
    "cv2.imshow(\"Dialation Image\",imgDialation)\n",
    "cv2.imshow(\"Eroded Image\",imgEroded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 623, 3)\n",
      "(200, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"image_examples/lambo.png\")\n",
    "print(img.shape)\n",
    "\n",
    "# Resizing the image\n",
    "imgResize = cv2.resize(src=img,dsize=(300,200)) # width 300 height 200\n",
    "print(imgResize.shape)\n",
    "cv2.imshow(\"Resize image\",imgResize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Cropped Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cropped img\n",
    "# 0:200 height\n",
    "#200:500 width\n",
    "imgCropped = img[0:200,200:500]\n",
    "\n",
    "cv2.imshow(\"Orginal image\",img)\n",
    "#cv2.imshow(\"Resize image\",imgResize)\n",
    "cv2.imshow(\"Cropped image\",imgCropped)\n",
    "cv2.waitKey(0) # 10000 millisecond == 10 second\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((512,512,3),np.uint8)\n",
    "#print(img)\n",
    "#img[:]= 255,0,0\n",
    " \n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)\n",
    "cv2.rectangle(img,(0,0),(250,350),(0,0,255),2)\n",
    "cv2.circle(img,(400,50),30,(255,255,0),5)\n",
    "cv2.putText(img,\" OPENCV  \",(300,200),cv2.FONT_HERSHEY_COMPLEX,1,(0,150,0),3)\n",
    " \n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectangle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @brief Draws a simple, thick, or filled up-right rectangle.\n",
    ".   \n",
    ".   The function cv::rectangle draws a rectangle outline or a filled rectangle whose two opposite corners\n",
    ".   are pt1 and pt2.\n",
    ".   \n",
    ".   @param img Image.\n",
    ".   @param pt1 Vertex of the rectangle.\n",
    ".   @param pt2 Vertex of the rectangle opposite to pt1 .\n",
    ".   @param color Rectangle color or brightness (grayscale image).\n",
    ".   @param thickness Thickness of lines that make up the rectangle. Negative values, like #FILLED,\n",
    ".   mean that the function has to draw a filled rectangle.\n",
    ".   @param lineType Type of the line. See #LineTypes\n",
    ".   @param shift Number of fractional bits in the point coordinates.\n",
    "\n",
    "\n",
    "\n",
    "rectangle(img, rec, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @overload\n",
    ".   \n",
    ".   use `rec` parameter as alternative specification of the drawn rectangle: `r.tl() and\n",
    ".   r.br()-Point(1,1)` are opposite corners\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.rectangle(img=color_img, pt1=(110,30), pt2=(337,221), color=(255,0,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to fill the rectangle with color then make thickness= -1 or negative value\n",
    "\n",
    "cv2.rectangle(img=color_img, pt1=(110,30), pt2=(337,221), color=(255,0,0), thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PutText"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) -> img\n",
    ".   @brief Draws a text string.\n",
    ".   \n",
    ".   The function cv::putText renders the specified text string in the image. Symbols that cannot be rendered\n",
    ".   using the specified font are replaced by question marks. See #getTextSize for a text rendering code\n",
    ".   example.\n",
    ".   \n",
    ".   @param img Image.\n",
    ".   @param text Text string to be drawn.\n",
    ".   @param org Bottom-left corner of the text string in the image.\n",
    ".   @param fontFace Font type, see #HersheyFonts.\n",
    ".   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
    ".   @param color Text color.\n",
    ".   @param thickness Thickness of the lines used to draw a text.\n",
    ".   @param lineType Line type. See #LineTypes\n",
    ".   @param bottomLeftOrigin When true, the image data origin is at the bottom-left corner. Otherwise,\n",
    ".   it is at the top-left corner.\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.rectangle(img=color_img, pt1=(110,30), pt2=(337,221), color=(255,0,255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.putText(img=color_img, text=\"Girl Face\", org=(110,25), \n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "            fontScale=2, color=(0,0,255), \n",
    "            thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.rectangle(img=color_img, pt1=(110,30), pt2=(337,221), color=(255,0,255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.putText(img=color_img, text=\"Girl Face\", org=(110,25), \n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "            fontScale=2, color=(0,0,255), \n",
    "            thickness=2, lineType=cv2.LINE_AA, bottomLeftOrigin=True) # bottomLeftOrigin = True it make the text oltaifelbe\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "circle(img, center, radius, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @brief Draws a circle.\n",
    ".   \n",
    ".   The function cv::circle draws a simple or filled circle with a given center and radius.\n",
    ".   @param img Image where the circle is drawn.\n",
    ".   @param center Center of the circle.\n",
    ".   @param radius Radius of the circle.\n",
    ".   @param color Circle color.\n",
    ".   @param thickness Thickness of the circle outline, if positive. Negative values, like #FILLED,\n",
    ".   mean that a filled circle is to be drawn.\n",
    ".   @param lineType Type of the circle boundary. See #LineTypes\n",
    ".   @param shift Number of fractional bits in the coordinates of the center and in the radius value.\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.circle(img=color_img, center=(211,153), radius=120, color=(0,255,254), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "line(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @brief Draws a line segment connecting two points.\n",
    ".   \n",
    ".   The function line draws the line segment between pt1 and pt2 points in the image. The line is\n",
    ".   clipped by the image boundaries. For non-antialiased lines with integer coordinates, the 8-connected\n",
    ".   or 4-connected Bresenham algorithm is used. Thick lines are drawn with rounding endings. Antialiased\n",
    ".   lines are drawn using Gaussian filtering.\n",
    ".   \n",
    ".   @param img Image.\n",
    ".   @param pt1 First point of the line segment.\n",
    ".   @param pt2 Second point of the line segment.\n",
    ".   @param color Line color.\n",
    ".   @param thickness Line thickness.\n",
    ".   @param lineType Type of the line. See #LineTypes.\n",
    ".   @param shift Number of fractional bits in the point coordinates.\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.line(img=color_img, pt1=(120,40), pt2=(500,40), color=(0,255,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ellipes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "ellipse(img, center, axes, angle, startAngle, endAngle, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @brief Draws a simple or thick elliptic arc or fills an ellipse sector.\n",
    ".   \n",
    ".   The function cv::ellipse with more parameters draws an ellipse outline, a filled ellipse, an elliptic\n",
    ".   arc, or a filled ellipse sector. The drawing code uses general parametric form.\n",
    ".   A piecewise-linear curve is used to approximate the elliptic arc\n",
    ".   boundary. If you need more control of the ellipse rendering, you can retrieve the curve using\n",
    ".   #ellipse2Poly and then render it with #polylines or fill it with #fillPoly. If you use the first\n",
    ".   variant of the function and want to draw the whole ellipse, not an arc, pass `startAngle=0` and\n",
    ".   `endAngle=360`. If `startAngle` is greater than `endAngle`, they are swapped. The figure below explains\n",
    ".   the meaning of the parameters to draw the blue arc.\n",
    ".   \n",
    ".   ![Parameters of Elliptic Arc](pics/ellipse.svg)\n",
    ".   \n",
    ".   @param img Image.\n",
    ".   @param center Center of the ellipse.\n",
    ".   @param axes Half of the size of the ellipse main axes.\n",
    ".   @param angle Ellipse rotation angle in degrees.\n",
    ".   @param startAngle Starting angle of the elliptic arc in degrees.\n",
    ".   @param endAngle Ending angle of the elliptic arc in degrees.\n",
    ".   @param color Ellipse color.\n",
    ".   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
    ".   a filled ellipse sector is to be drawn.\n",
    ".   @param lineType Type of the ellipse boundary. See #LineTypes\n",
    ".   @param shift Number of fractional bits in the coordinates of the center and values of axes.\n",
    "\n",
    "\n",
    "\n",
    "ellipse(img, box, color[, thickness[, lineType]]) -> img\n",
    ".   @overload\n",
    ".   @param img Image.\n",
    ".   @param box Alternative ellipse representation via RotatedRect. This means that the function draws\n",
    ".   an ellipse inscribed in the rotated rectangle.\n",
    ".   @param color Ellipse color.\n",
    ".   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
    ".   a filled ellipse sector is to be drawn.\n",
    ".   @param lineType Type of the ellipse boundary. See #LineTypes\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "cv2.ellipse(img=color_img, center=(211,153), \n",
    "            axes=(100,150), angle=30, \n",
    "            startAngle=0, endAngle=360, \n",
    "            color=(255,2,255), thickness=2)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygons"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]]) -> img\n",
    ".   @brief Draws several polygonal curves.\n",
    ".   \n",
    ".   @param img Image.\n",
    ".   @param pts Array of polygonal curves.\n",
    ".   @param isClosed Flag indicating whether the drawn polylines are closed or not. If they are closed,\n",
    ".   the function draws a line from the last vertex of each curve to its first vertex.\n",
    ".   @param color Polyline color.\n",
    ".   @param thickness Thickness of the polyline edges.\n",
    ".   @param lineType Type of the line segments. See #LineTypes\n",
    ".   @param shift Number of fractional bits in the vertex coordinates.\n",
    ".   \n",
    ".   The function cv::polylines draws one or more polygonal curves.\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is  an octagon\n",
    "# You can draw line, triangle, rectangle by this function\n",
    "\n",
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "pts = np.array([[25, 70], [25, 145], \n",
    "                [75, 190], [150, 190], \n",
    "                [200, 145], [200, 70],  \n",
    "                [150, 25], [75, 25]], \n",
    "               np.int32)\n",
    "\n",
    "cv2.polylines(img=color_img, pts=[pts], isClosed=True, color=(122,25,255), thickness=2)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is  an octagon\n",
    "# You can draw line, triangle, rectangle by this function\n",
    "\n",
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "pts = np.array([[25, 70], [25, 145], \n",
    "                [75, 190], [150, 190], \n",
    "                [200, 145], [200, 70],  \n",
    "                [150, 25], [75, 25]], \n",
    "               np.int32)\n",
    "# if isClosed = False then the polygons not complete the edges\n",
    "cv2.polylines(img=color_img, pts=[pts], isClosed=False, color=(122,25,255), thickness=2)\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=color_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
    ".   @brief Blurs an image using the normalized box filter.\n",
    ".   \n",
    ".   The function smooths an image using the kernel:\n",
    ".   \n",
    ".   \\f[\\texttt{K} =  \\frac{1}{\\texttt{ksize.width*ksize.height}} \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\end{bmatrix}\\f]\n",
    ".   \n",
    ".   The call `blur(src, dst, ksize, anchor, borderType)` is equivalent to `boxFilter(src, dst, src.type(), ksize,\n",
    ".   anchor, true, borderType)`.\n",
    ".   \n",
    ".   @param src input image; it can have any number of channels, which are processed independently, but\n",
    ".   the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
    ".   @param dst output image of the same size and type as src.\n",
    ".   @param ksize blurring kernel size.\n",
    ".   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
    ".   center.\n",
    ".   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported.\n",
    ".   @sa  boxFilter, bilateralFilter, GaussianBlur, medianBlur\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "# If you increase size then blur will be increase\n",
    "img_blur = cv2.blur(src=color_img, ksize=(10,10))\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=img_blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxfilter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
    ".   @brief Blurs an image using the box filter.\n",
    ".   \n",
    ".   The function smooths an image using the kernel:\n",
    ".   \n",
    ".   \\f[\\texttt{K} =  \\alpha \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1 \\end{bmatrix}\\f]\n",
    ".   \n",
    ".   where\n",
    ".   \n",
    ".   \\f[\\alpha = \\begin{cases} \\frac{1}{\\texttt{ksize.width*ksize.height}} & \\texttt{when } \\texttt{normalize=true}  \\\\1 & \\texttt{otherwise}\\end{cases}\\f]\n",
    ".   \n",
    ".   Unnormalized box filter is useful for computing various integral characteristics over each pixel\n",
    ".   neighborhood, such as covariance matrices of image derivatives (used in dense optical flow\n",
    ".   algorithms, and so on). If you need to compute pixel sums over variable-size windows, use #integral.\n",
    ".   \n",
    ".   @param src input image.\n",
    ".   @param dst output image of the same size and type as src.\n",
    ".   @param ddepth the output image depth (-1 to use src.depth()).\n",
    ".   @param ksize blurring kernel size.\n",
    ".   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
    ".   center.\n",
    ".   @param normalize flag, specifying whether the kernel is normalized by its area or not.\n",
    ".   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported.\n",
    ".   @sa  blur, bilateralFilter, GaussianBlur, medianBlur, integral\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "# If you increase size then blur will be increase\n",
    "# If normalize False image will be not show in the window\n",
    "\n",
    "img_blur = cv2.boxFilter(src=color_img, ddepth=-1 , ksize=(40,40), normalize=True) # by-default normalize is True.\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=img_blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "# If you increase size then blur will be increase\n",
    "img_blur = cv2.boxFilter(src=color_img, ddepth=-1 , ksize=(70,20))\n",
    "\n",
    "cv2.imshow(winname=\"Girl Image\", mat=img_blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bluring image using filter2d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Docstring:\n",
    "filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
    ".   @brief Convolves an image with the kernel.\n",
    ".   \n",
    ".   The function applies an arbitrary linear filter to an image. In-place operation is supported. When\n",
    ".   the aperture is partially outside the image, the function interpolates outlier pixel values\n",
    ".   according to the specified border mode.\n",
    ".   \n",
    ".   The function does actually compute correlation, not the convolution:\n",
    ".   \n",
    ".   \\f[\\texttt{dst} (x,y) =  \\sum _{ \\substack{0\\leq x' < \\texttt{kernel.cols}\\\\{0\\leq y' < \\texttt{kernel.rows}}}}  \\texttt{kernel} (x',y')* \\texttt{src} (x+x'- \\texttt{anchor.x} ,y+y'- \\texttt{anchor.y} )\\f]\n",
    ".   \n",
    ".   That is, the kernel is not mirrored around the anchor point. If you need a real convolution, flip\n",
    ".   the kernel using #flip and set the new anchor to `(kernel.cols - anchor.x - 1, kernel.rows -\n",
    ".   anchor.y - 1)`.\n",
    ".   \n",
    ".   The function uses the DFT-based algorithm in case of sufficiently large kernels (~`11 x 11` or\n",
    ".   larger) and the direct algorithm for small kernels.\n",
    ".   \n",
    ".   @param src input image.\n",
    ".   @param dst output image of the same size and the same number of channels as src.\n",
    ".   @param ddepth desired depth of the destination image, see @ref filter_depths \"combinations\"\n",
    ".   @param kernel convolution kernel (or rather a correlation kernel), a single-channel floating point\n",
    ".   matrix; if you want to apply different kernels to different channels, split the image into\n",
    ".   separate color planes using split and process them individually.\n",
    ".   @param anchor anchor of the kernel that indicates the relative position of a filtered point within\n",
    ".   the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor\n",
    ".   is at the kernel center.\n",
    ".   @param delta optional value added to the filtered pixels before storing them in dst.\n",
    ".   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
    ".   @sa  sepFilter2D, dft, matchTemplate\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur Image using Filter2D with 5×5 kernel\n",
    "\n",
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "one_mat_5_5 = np.ones((5,5), dtype=np.float32)/25\n",
    "\n",
    "blur_img_5_5 = cv2.filter2D(src=color_img, ddepth=-1, kernel=one_mat_5_5)\n",
    " \n",
    " \n",
    "cv2.imshow(\"Blure image 5x5\", blur_img_5_5)\n",
    "# cv2.imshow(\"Original Image\", img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50*50\n",
    "color_img = cv2.imread(filename=\"image_examples/girl.png\")\n",
    "\n",
    "one_mat_50_50 = np.ones((50,50), dtype=np.float32)/2500\n",
    " \n",
    "blur_img_50_50 = cv2.filter2D(src=color_img, ddepth=-1, kernel=one_mat_50_50)\n",
    " \n",
    "# cv2.imshow(\"Original Image\", color_img)\n",
    "cv2.imshow(\"Blure Image using\", blur_img_50_50)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Warp Perspective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image_examples/cards.jpg\")\n",
    "\n",
    "width,height = 250,350\n",
    "pts1 = np.float32([[111,219],[287,188],[154,482],[352,440]])\n",
    "pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "imgOutput = cv2.warpPerspective(src=img,M=matrix,dsize=(width,height))\n",
    "\n",
    "cv2.imshow(\"Cards Image\",img)\n",
    "cv2.imshow(\"Output Image\",imgOutput)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Joining Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(filename=\"image_examples/lena.png\")\n",
    "img_resize = cv2.resize(src=img,dsize=(300,300))\n",
    "imgHorizontal = np.hstack((img_resize,img_resize))\n",
    "imgVertical = np.vstack((img_resize,img_resize))\n",
    "cv2.imshow(\"Orginal Image\",img)\n",
    "cv2.imshow(\"imgHorizontal Image\",imgHorizontal)\n",
    "cv2.imshow(\"imgVertical Image\",imgVertical)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
